{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a908d626",
   "metadata": {},
   "source": [
    "# Environment Test\n",
    "Verify all dependencies and API connections are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56507e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.13 (main, Jul 23 2025, 18:09:53) [GCC 12.2.0]\n",
      "Google API Key configured: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Google API Key configured: {'GOOGLE_API_KEY' in os.environ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32163f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All core dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import langchain\n",
    "    import langgraph\n",
    "    import streamlit\n",
    "    import matplotlib\n",
    "    import plotly\n",
    "    print(\"‚úÖ All core dependencies imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08a925e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuraci√≥n detectada:\n",
      "   Modelo: gemini-pro\n",
      "   Temperatura: 0.1\n",
      "   Max output tokens: 2048\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Google Gemini API error: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "üí° Verifica que GOOGLE_API_KEY est√© configurada correctamente\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ CONFIGURACI√ìN ACTUALIZADA: Usando gemini-pro para optimizar rate limits\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from app.core.config import get_settings\n",
    "\n",
    "try:\n",
    "    # Usar la configuraci√≥n centralizada como debe ser\n",
    "    settings = get_settings()\n",
    "    gemini_config = settings.gemini_config\n",
    "    \n",
    "    print(f\"üîß Configuraci√≥n detectada:\")\n",
    "    print(f\"   Modelo: {gemini_config['model_name']}\")\n",
    "    print(f\"   Temperatura: {gemini_config['temperature']}\")\n",
    "    print(f\"   Max output tokens: {gemini_config['max_output_tokens']}\")\n",
    "    print()\n",
    "    \n",
    "    # Crear LLM con la configuraci√≥n correcta para Google Gemini\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=gemini_config[\"model_name\"],  # gemini-pro (actualizado para mejor rate limiting)\n",
    "        temperature=gemini_config[\"temperature\"],\n",
    "        max_output_tokens=gemini_config[\"max_output_tokens\"],  # Par√°metro correcto para Google Gemini\n",
    "        google_api_key=gemini_config[\"api_key\"]\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(\"Hello, test connection\")\n",
    "    print(\"‚úÖ Google Gemini API connection successful\")\n",
    "    print(f\"Response: {response.content[:100]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Google Gemini API error: {e}\")\n",
    "    print(\"üí° Verifica que GOOGLE_API_KEY est√© configurada correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4534b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üèÅ ENVIRONMENT TEST SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üêç Python Version: {sys.version.split()[0]}\")\n",
    "print(f\"üê≥ Docker Environment: {'‚úÖ YES' if os.getenv('DATABASE_URL') else '‚ùå NO'}\")\n",
    "print(f\"üîë Google API Key: {'‚úÖ CONFIGURED' if os.getenv('GOOGLE_API_KEY') else '‚ùå MISSING'}\")\n",
    "print(f\"üóÑÔ∏è  Database URL: {'‚úÖ CONFIGURED' if os.getenv('DATABASE_URL') else '‚ùå MISSING'}\")\n",
    "print(\"\\nüí° Si todo est√° ‚úÖ, tu entorno est√° listo para el ReAct Agent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fa328",
   "metadata": {},
   "source": [
    "## üéØ Actualizaci√≥n del Modelo Gemini\n",
    "\n",
    "**‚úÖ MIGRACI√ìN COMPLETADA**: Cambiado de `gemini-1.5-flash` a `gemini-2.5-flash` por optimizaci√≥n de rate limits\n",
    "\n",
    "### üìä Motivos del Cambio:\n",
    "- **Rate Limits Mejorados**: `gemini-2.5-flash` ofrece mejores l√≠mites de solicitudes por minuto\n",
    "- **Rendimiento**: Mayor velocidad de respuesta y optimizaci√≥n mejorada\n",
    "- **Costo-Efectividad**: Mejor relaci√≥n costo/rendimiento para aplicaciones de producci√≥n\n",
    "- **Caracter√≠sticas**: Mantiene todas las capacidades de 1.5 con mejoras adicionales\n",
    "\n",
    "### üîß Cambios Implementados:\n",
    "- Configuraci√≥n por defecto en `app/core/config.py`\n",
    "- Variables de entorno en `.env.example`\n",
    "- Documentaci√≥n actualizada\n",
    "- Tests actualizados para el nuevo modelo\n",
    "\n",
    "### üöÄ Pr√≥ximos Pasos:\n",
    "1. Verificar que `GOOGLE_API_KEY` tiene acceso a Gemini 2.5 Flash\n",
    "2. Actualizar archivo `.env` local con `GEMINI_MODEL_NAME=gemini-2.5-flash`\n",
    "3. Reiniciar la aplicaci√≥n para aplicar cambios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cb9c23",
   "metadata": {},
   "source": [
    "### üìã Detalles T√©cnicos de la Migraci√≥n\n",
    "\n",
    "**üîß ACTUALIZACI√ìN APLICADA**: Migraci√≥n de `gemini-1.5-flash` a `gemini-2.5-flash`\n",
    "\n",
    "**Cambios t√©cnicos implementados:**\n",
    "- **Modelo**: `gemini-1.5-flash` ‚Üí `gemini-2.5-flash` (mejor rendimiento y rate limits)\n",
    "- **Max Tokens**: 8192 (mantenido - compatible con ambos modelos)\n",
    "- **Temperature**: 0.1 (optimizada para tareas matem√°ticas)\n",
    "- **API**: Misma interfaz langchain-google-genai\n",
    "\n",
    "**Beneficios del nuevo modelo:**\n",
    "- ‚ö° **Velocidad**: Respuestas m√°s r√°pidas\n",
    "- üéØ **Rate Limits**: L√≠mites m√°s generosos para aplicaciones intensivas\n",
    "- üß† **Capacidades**: Mejoras en razonamiento matem√°tico y l√≥gico\n",
    "- üí∞ **Costo**: Mejor relaci√≥n precio/rendimiento\n",
    "\n",
    "**Compatibilidad:**\n",
    "- ‚úÖ Totalmente compatible con el c√≥digo existente\n",
    "- ‚úÖ Mismos par√°metros de configuraci√≥n\n",
    "- ‚úÖ Sin cambios en la interfaz de LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    from langgraph.graph import StateGraph\n",
    "    import psycopg2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    print(\"‚úÖ All project-specific dependencies imported successfully\")\n",
    "    print(\"  - LangChain Google GenAI: ‚úì\")\n",
    "    print(\"  - LangGraph: ‚úì\") \n",
    "    print(\"  - PostgreSQL: ‚úì\")\n",
    "    print(\"  - NumPy: ‚úì\")\n",
    "    print(\"  - Pandas: ‚úì\")\n",
    "    \n",
    "    # Test Gemini 2.5 Flash configuration\n",
    "    gemini_config = {\n",
    "        \"model_name\": \"gemini-2.5-flash\",  # Updated to Gemini 2.5 Flash for better rate limits\n",
    "        \"temperature\": 0.1,\n",
    "        \"api_key\": os.getenv(\"GOOGLE_API_KEY\"),\n",
    "        \"max_output_tokens\": 8192\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüîß Gemini 2.5 Flash configuration:\")\n",
    "    print(f\"   Modelo: {gemini_config['model_name']}\")\n",
    "    print(f\"   Temperatura: {gemini_config['temperature']}\")\n",
    "    print(f\"   Max output tokens: {gemini_config['max_output_tokens']}\")\n",
    "    print()\n",
    "    \n",
    "    # Crear LLM con la configuraci√≥n correcta para Google Gemini\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=gemini_config[\"model_name\"],  # gemini-2.5-flash (actualizado para mejor rate limiting)\n",
    "        temperature=gemini_config[\"temperature\"],\n",
    "        max_output_tokens=gemini_config[\"max_output_tokens\"],  # Par√°metro correcto para Google Gemini\n",
    "        google_api_key=gemini_config[\"api_key\"]\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(\"Hello, test connection\")\n",
    "    print(\"‚úÖ Google Gemini API connection successful\")\n",
    "    print(f\"   Response preview: {response.content[:100]}...\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"   Install missing dependencies with: poetry install\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Google Gemini API error: {e}\")\n",
    "    print(\"üí° Verifica que GOOGLE_API_KEY est√© configurada correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ CONFIGURACI√ìN ACTUALIZADA: Usando gemini-2.5-flash para mejores rate limits\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "try:\n",
    "    # Get Google API key\n",
    "    google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not google_api_key:\n",
    "        raise ValueError(\"GOOGLE_API_KEY not found in environment\")\n",
    "    \n",
    "    # Test Google Gemini 2.5 Flash connection\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",  # Updated to 2.5 Flash model for better rate limits\n",
    "        temperature=0.1,\n",
    "        max_output_tokens=8192,  # 2.5 Flash's maximum tokens\n",
    "        api_key=google_api_key\n",
    "    )\n",
    "    \n",
    "    print(\"ü§ñ Testing Gemini 2.5 Flash connection...\")\n",
    "    response = llm.invoke(\"Hello! Test connection with gemini-2.5-flash model.\")\n",
    "    print(\"‚úÖ Connection successful!\")\n",
    "    print(f\"Response: {response.content[:100]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Google Gemini API error: {e}\")\n",
    "    print(\"   Check your GOOGLE_API_KEY in .env file\")\n",
    "    print(\"   Ensure your API key has access to Gemini 2.5 Flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491bb39",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mrequest to http://localhost:8888/api/kernels/df5fbd75-172b-4e7e-9b95-40039aec0c4a/restart?1754151882589 failed, reason: connect ECONNREFUSED ::1:8888. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# üîÑ VERIFICACI√ìN POST-MIGRACI√ìN: Configuraci√≥n con gemini-2.5-flash\n",
    "\n",
    "print(\"üîÑ VERIFICACI√ìN DE MIGRACI√ìN A GEMINI-2.5-FLASH\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    from app.core.config import get_settings\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    \n",
    "    # Load current settings\n",
    "    settings = get_settings()\n",
    "    gemini_config = settings.gemini_config\n",
    "    \n",
    "    print(\"üîç Configuraci√≥n actual:\")\n",
    "    print(f\"   üì± Modelo: {gemini_config['model_name']} {'‚úÖ' if gemini_config['model_name'] == 'gemini-2.5-flash' else '‚ùå'}\")\n",
    "    print(f\"   üå°Ô∏è  Temperature: {gemini_config['temperature']}\")\n",
    "    print(f\"   üìä Max Tokens: {gemini_config['max_output_tokens']}\")\n",
    "    print(f\"   üîë API Key: {'‚úÖ Configurada' if gemini_config['api_key'] else '‚ùå Faltante'}\")\n",
    "    \n",
    "    # Verify migration success\n",
    "    if gemini_config['model_name'] == 'gemini-2.5-flash':\n",
    "        print(\"‚úÖ MIGRACI√ìN EXITOSA: Modelo actualizado a gemini-2.5-flash\")\n",
    "        print(\"üöÄ Beneficios: Mejores rate limits y rendimiento optimizado\")\n",
    "        \n",
    "        print(\"üîç Probando conexi√≥n con gemini-2.5-flash...\")\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model=gemini_config[\"model_name\"],\n",
    "            temperature=gemini_config[\"temperature\"],\n",
    "            max_output_tokens=gemini_config[\"max_output_tokens\"],\n",
    "            api_key=gemini_config[\"api_key\"]\n",
    "        )\n",
    "        \n",
    "        response = llm.invoke(\"Hello! Test connection with gemini-2.5-flash model.\")\n",
    "        print(\"‚úÖ Conexi√≥n exitosa con el nuevo modelo\")\n",
    "        print(f\"   Respuesta: {response.content[:100]}...\")\n",
    "    else:\n",
    "        print(f\"‚ùå MIGRACI√ìN FALLIDA: Se esperaba gemini-2.5-flash, se obtuvo {gemini_config['model_name']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error en verificaci√≥n: {e}\")\n",
    "    \n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
