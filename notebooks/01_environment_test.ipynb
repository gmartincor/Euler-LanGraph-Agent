{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a908d626",
   "metadata": {},
   "source": [
    "# Environment Test\n",
    "Verify all dependencies and API connections are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56507e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.13 (main, Jul 23 2025, 18:09:53) [GCC 12.2.0]\n",
      "Google API Key configured: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Google API Key configured: {'GOOGLE_API_KEY' in os.environ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32163f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All core dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import langchain\n",
    "    import langgraph\n",
    "    import streamlit\n",
    "    import matplotlib\n",
    "    import plotly\n",
    "    print(\"âœ… All core dependencies imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a925e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ConfiguraciÃ³n detectada:\n",
      "   Modelo: gemini-pro\n",
      "   Temperatura: 0.1\n",
      "   Max tokens: 8192\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Google Gemini API error: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "ğŸ’¡ Verifica que GOOGLE_API_KEY estÃ© configurada correctamente\n"
     ]
    }
   ],
   "source": [
    "# âœ… CONFIGURACIÃ“N ACTUALIZADA: Usando gemini-pro para optimizar rate limits\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from app.core.config import get_settings\n",
    "\n",
    "try:\n",
    "    # Usar la configuraciÃ³n centralizada como debe ser\n",
    "    settings = get_settings()\n",
    "    gemini_config = settings.gemini_config\n",
    "    \n",
    "    print(f\"ğŸ”§ ConfiguraciÃ³n detectada:\")\n",
    "    print(f\"   Modelo: {gemini_config['model_name']}\")\n",
    "    print(f\"   Temperatura: {gemini_config['temperature']}\")\n",
    "    print(f\"   Max output tokens: {gemini_config['max_output_tokens']}\")\n",
    "    print()\n",
    "    \n",
    "    # Crear LLM con la configuraciÃ³n correcta para Google Gemini\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=gemini_config[\"model_name\"],  # gemini-pro (actualizado para mejor rate limiting)\n",
    "        temperature=gemini_config[\"temperature\"],\n",
    "        max_output_tokens=gemini_config[\"max_output_tokens\"],  # ParÃ¡metro correcto para Google Gemini\n",
    "        google_api_key=gemini_config[\"api_key\"]\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(\"Hello, test connection\")\n",
    "    print(\"âœ… Google Gemini API connection successful\")\n",
    "    print(f\"Response: {response.content[:100]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Google Gemini API error: {e}\")\n",
    "    print(\"ğŸ’¡ Verifica que GOOGLE_API_KEY estÃ© configurada correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4534b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ ENVIRONMENT TEST SUMMARY\n",
      "==================================================\n",
      "ğŸ Python Version: 3.11.13\n",
      "ğŸ³ Docker Environment: âœ… YES\n",
      "ğŸ”‘ Google API Key: âœ… CONFIGURED\n",
      "ğŸ—„ï¸  Database URL: âœ… CONFIGURED\n",
      "\n",
      "ğŸ’¡ Si todo estÃ¡ âœ…, tu entorno estÃ¡ listo para el ReAct Agent!\n"
     ]
    }
   ],
   "source": [
    "# Environment Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ ENVIRONMENT TEST SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ğŸ Python Version: {sys.version.split()[0]}\")\n",
    "print(f\"ğŸ³ Docker Environment: {'âœ… YES' if os.getenv('DATABASE_URL') else 'âŒ NO'}\")\n",
    "print(f\"ğŸ”‘ Google API Key: {'âœ… CONFIGURED' if os.getenv('GOOGLE_API_KEY') else 'âŒ MISSING'}\")\n",
    "print(f\"ğŸ—„ï¸  Database URL: {'âœ… CONFIGURED' if os.getenv('DATABASE_URL') else 'âŒ MISSING'}\")\n",
    "print(\"\\nğŸ’¡ Si todo estÃ¡ âœ…, tu entorno estÃ¡ listo para el ReAct Agent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fa328",
   "metadata": {},
   "source": [
    "## ğŸ¯ ActualizaciÃ³n del Modelo Gemini\n",
    "\n",
    "**âœ… MIGRACIÃ“N COMPLETADA**: Cambiado de `gemini-1.5-pro` a `gemini-pro` por optimizaciÃ³n de rate limits\n",
    "\n",
    "### ğŸ“Š Motivos del Cambio:\n",
    "- **Rate Limits Mejorados**: `gemini-pro` ofrece 60 requests/minuto vs lÃ­mites mÃ¡s estrictos de `1.5-pro`\n",
    "- **Costos Optimizados**: Modelo mÃ¡s econÃ³mico para casos de uso de desarrollo y testing\n",
    "- **Compatibilidad**: Totalmente compatible con el stack actual de LangChain\n",
    "\n",
    "### ğŸ”§ Cambios Realizados:\n",
    "- âœ… ConfiguraciÃ³n principal (`.env`) actualizada\n",
    "- âœ… ConfiguraciÃ³n por defecto (`config.py`) modificada  \n",
    "- âœ… Tests unitarios actualizados\n",
    "- âœ… Archivos de ejemplo sincronizados\n",
    "- âœ… DocumentaciÃ³n actualizada\n",
    "\n",
    "### ğŸš€ PrÃ³ximos Pasos:\n",
    "1. **Reiniciar servicios**: `make restart` para aplicar cambios\n",
    "2. **Ejecutar tests**: `make test` para validar funcionalidad\n",
    "3. **Monitorear performance**: Verificar que el nuevo modelo cumple expectativas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cb9c23",
   "metadata": {},
   "source": [
    "## âš™ï¸ CorrecciÃ³n TÃ©cnica: ParÃ¡metros de Google Gemini\n",
    "\n",
    "**ğŸ”§ PARÃMETRO CORREGIDO**: Uso de `max_output_tokens` en lugar de `max_tokens`\n",
    "\n",
    "### ğŸ“‹ Diferencias Importantes:\n",
    "- **OpenAI LangChain**: Usa `max_tokens` \n",
    "- **Google Gemini LangChain**: Usa `max_output_tokens`\n",
    "- **Motivo**: Cada proveedor tiene su propia implementaciÃ³n en LangChain\n",
    "\n",
    "### âœ… Cambios Aplicados:\n",
    "- âœ… `app/core/config.py`: Actualizado property `gemini_config`\n",
    "- âœ… Notebook: Actualizado cÃ³digo de conexiÃ³n\n",
    "- âœ… DocumentaciÃ³n: AÃ±adida explicaciÃ³n tÃ©cnica\n",
    "\n",
    "### ğŸš¨ Impacto:\n",
    "- **Antes**: Posibles errores silenciosos con parÃ¡metro incorrecto\n",
    "- **DespuÃ©s**: ConfiguraciÃ³n precisa y compatible con Google Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233e2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All project-specific dependencies imported successfully\n",
      "  - LangChain Google GenAI: âœ“\n",
      "  - LangGraph: âœ“\n",
      "  - PostgreSQL driver: âœ“\n",
      "  - NumPy & Pandas: âœ“\n"
     ]
    }
   ],
   "source": [
    "# Test specific project dependencies\n",
    "try:\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    from langgraph.graph import StateGraph\n",
    "    import psycopg2\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    print(\"âœ… All project-specific dependencies imported successfully\")\n",
    "    print(\"  - LangChain Google GenAI: âœ“\")\n",
    "    print(\"  - LangGraph: âœ“\") \n",
    "    print(\"  - PostgreSQL driver: âœ“\")\n",
    "    print(\"  - NumPy & Pandas: âœ“\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Project dependency error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ VERIFICACIÃ“N POST-REINICIO: ConfiguraciÃ³n con gemini-pro\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ”„ VERIFICACIÃ“N DE MIGRACIÃ“N A GEMINI-PRO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Importar configuraciÃ³n fresh (despuÃ©s del reinicio de Docker)\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Reload modules to get fresh configuration\n",
    "if 'app.core.config' in sys.modules:\n",
    "    importlib.reload(sys.modules['app.core.config'])\n",
    "\n",
    "from app.core.config import get_settings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "try:\n",
    "    # Obtener configuraciÃ³n actualizada\n",
    "    settings = get_settings()\n",
    "    gemini_config = settings.gemini_config\n",
    "    \n",
    "    print(f\"ğŸ”§ ConfiguraciÃ³n Actual:\")\n",
    "    print(f\"   ğŸ“± Modelo: {gemini_config['model_name']} {'âœ…' if gemini_config['model_name'] == 'gemini-pro' else 'âŒ'}\")\n",
    "    print(f\"   ğŸŒ¡ï¸  Temperatura: {gemini_config['temperature']}\")\n",
    "    print(f\"   ğŸ“Š Max output tokens: {gemini_config['max_output_tokens']}\")\n",
    "    print(f\"   ğŸ”‘ API Key: {'âœ… Configurada' if gemini_config['api_key'] else 'âŒ Faltante'}\")\n",
    "    print()\n",
    "    \n",
    "    if gemini_config['model_name'] == 'gemini-pro':\n",
    "        print(\"âœ… MIGRACIÃ“N EXITOSA: Modelo actualizado a gemini-pro\")\n",
    "        \n",
    "        # Test connection with new model using correct parameter\n",
    "        print(\"ğŸ” Probando conexiÃ³n con gemini-pro...\")\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model=gemini_config[\"model_name\"],\n",
    "            temperature=gemini_config[\"temperature\"], \n",
    "            max_output_tokens=gemini_config[\"max_output_tokens\"],  # ParÃ¡metro correcto para Google Gemini\n",
    "            google_api_key=gemini_config[\"api_key\"]\n",
    "        )\n",
    "        \n",
    "        response = llm.invoke(\"Hello! Test connection with gemini-pro model.\")\n",
    "        print(\"âœ… ConexiÃ³n exitosa con gemini-pro!\")\n",
    "        print(f\"ğŸ“ Respuesta: {response.content[:150]}...\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ MIGRACIÃ“N FALLIDA: AÃºn usando {gemini_config['model_name']}\")\n",
    "        print(\"ğŸ’¡ Puede necesitar reiniciar el kernel del notebook\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error en la verificaciÃ³n: {e}\")\n",
    "    if \"429\" in str(e):\n",
    "        print(\"ğŸ’¡ Error de cuota - esperado si gemini-1.5-pro sigue activo\")\n",
    "        print(\"ğŸ”„ Reinicia el kernel del notebook para aplicar cambios\")\n",
    "    else:\n",
    "        print(\"ğŸ’¡ Verifica la configuraciÃ³n del API key\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
